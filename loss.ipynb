{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 4573338 characters\n",
      "Vocabulary size: 67 characters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras import optimizers\n",
    "import argparse\n",
    "from RNN_utils import *\n",
    "\n",
    "DATA_DIR = './data/shakespeare_input.txt'\n",
    "BATCH_SIZE = 50\n",
    "HIDDEN_DIM = 500\n",
    "SEQ_LENGTH = 50\n",
    "\n",
    "WEIGHTS = './checkpoints/shakespeare/checkpoint_layer_2_hidden_500_epoch_30.hdf5'\n",
    "\n",
    "GENERATE_LENGTH = 100\n",
    "LAYER_NUM = 2\n",
    "\n",
    "# Creating training data\n",
    "X, y, VOCAB_SIZE, ix_to_char, char_to_ix = load_data(DATA_DIR, SEQ_LENGTH)\n",
    "\n",
    "# Creating and compiling the Network\n",
    "model = Sequential()\n",
    "model.add(LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "for i in range(LAYER_NUM - 1):\n",
    "  model.add(LSTM(HIDDEN_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "model.add(Activation('softmax'))\n",
    "rms_prop = optimizers.RMSprop(lr=1e-4)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=rms_prop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will not serve your highness.\n",
      "\n",
      "KING HENRY VI:\n",
      "Why,"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'will not serve your highness.\\n\\nKING HENRY VI:\\nWhy, '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, 50, VOCAB_SIZE, ix_to_char, -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 4s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X[0:1000], y[0:1000], batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9429967308044434"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X[0:1000], batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.17197190e-03, 4.44228772e-06, 9.64791849e-02, ...,\n",
       "        3.90033747e-05, 2.10114400e-15, 1.54810857e-14],\n",
       "       [2.65368023e-12, 1.13360467e-10, 1.68790123e-07, ...,\n",
       "        2.50070755e-08, 1.71444654e-08, 1.60197813e-10],\n",
       "       [7.79449749e-07, 7.74046285e-08, 1.21229270e-03, ...,\n",
       "        6.33377931e-06, 5.10936779e-11, 8.11284254e-13],\n",
       "       ...,\n",
       "       [1.34529024e-02, 7.35918002e-05, 2.49676764e-01, ...,\n",
       "        1.71993906e-06, 2.92425767e-07, 1.07904576e-07],\n",
       "       [1.36714118e-06, 8.10519651e-09, 2.57816100e-06, ...,\n",
       "        1.00034910e-07, 1.40876547e-12, 1.19446629e-12],\n",
       "       [5.67603623e-03, 3.61252273e-06, 4.81477827e-01, ...,\n",
       "        1.15995485e-04, 1.34822319e-14, 6.83095412e-14]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "sess = K.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_ce = tf.reduce_mean(losses.categorical_crossentropy(y[0:1000], tf.convert_to_tensor(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9429928\n"
     ]
    }
   ],
   "source": [
    "print(c_ce.eval(session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lossfile = './data/shakespeare_loss.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating loss with the following excerpt:\n",
      "\n",
      "BASTARD:\n",
      "O, let us pay the time but needful woe,\n",
      "Since it hath been beforehand with our griefs.\n",
      "This England never did, nor never shall,\n",
      "Lie at the proud foot of a conqueror,\n",
      "But when it first did help to wound itself.\n",
      "Now these her princes are come home again,\n",
      "Come the three corners of the world in arms,\n",
      "And we shall shock them. Nought shall make us rue,\n",
      "If England to itself do rest but true.\n",
      "\n",
      "Char:  A  Loss:  5.4790745   Loss so far:  5.479074478149414\n",
      "Char:  S  Loss:  3.1051233   Loss so far:  4.292098879814148\n",
      "Char:  T  Loss:  19.35714   Loss so far:  9.31377911567688\n",
      "Char:  A  Loss:  9.32033   Loss so far:  9.315416753292084\n",
      "Char:  R  Loss:  10.781898   Loss so far:  9.608712911605835\n",
      "Char:  D  Loss:  28.760984   Loss so far:  12.800758163134256\n",
      "Char:  :  Loss:  2.726393   Loss so far:  11.3615631375994\n",
      "Char:  \n",
      "  Loss:  1.5445459   Loss so far:  10.13443598151207\n",
      "Char:  O  Loss:  9.781141   Loss so far:  10.095181014802721\n",
      "Char:  ,  Loss:  4.6743126   Loss so far:  9.553094172477723\n",
      "Char:     Loss:  3.021853   Loss so far:  8.959344972263683\n",
      "Char:  l  Loss:  3.1248324   Loss so far:  8.473135590553284\n",
      "Char:  e  Loss:  10.272308   Loss so far:  8.61153349509606\n",
      "Char:  t  Loss:  8.403752   Loss so far:  8.596691983086723\n",
      "Char:     Loss:  10.127534   Loss so far:  8.698748111724854\n",
      "Char:  u  Loss:  7.326541   Loss so far:  8.612985163927078\n",
      "Char:  s  Loss:  6.807432   Loss so far:  8.506776164559756\n",
      "Char:     Loss:  2.6426213   Loss so far:  8.180989782015482\n",
      "Char:  p  Loss:  12.193207   Loss so far:  8.392159098073057\n",
      "Char:  a  Loss:  1.6922114   Loss so far:  8.057161712646485\n",
      "Char:  y  Loss:  13.972371   Loss so far:  8.338838350205194\n",
      "Char:     Loss:  2.9393198   Loss so far:  8.093405691060154\n",
      "Char:  t  Loss:  10.894182   Loss so far:  8.215178582979286\n",
      "Char:  h  Loss:  4.565277   Loss so far:  8.063099354505539\n",
      "Char:  e  Loss:  4.5499835   Loss so far:  7.92257472038269\n",
      "Char:     Loss:  0.1314869   Loss so far:  7.622917496241056\n",
      "Char:  t  Loss:  11.330698   Loss so far:  7.760242700576782\n",
      "Char:  i  Loss:  3.1751564   Loss so far:  7.596489616802761\n",
      "Char:  m  Loss:  15.109598   Loss so far:  7.855562325181632\n",
      "Char:  e  Loss:  1.8605528   Loss so far:  7.655728673934936\n",
      "Char:     Loss:  2.5769987   Loss so far:  7.4918986751187235\n",
      "Char:  b  Loss:  13.741239   Loss so far:  7.687190547585487\n",
      "Char:  u  Loss:  10.936294   Loss so far:  7.785648215900768\n",
      "Char:  t  Loss:  9.334431   Loss so far:  7.831200641744277\n",
      "Char:     Loss:  0.4530518   Loss so far:  7.620396389280047\n",
      "Char:  n  Loss:  8.866027   Loss so far:  7.654997236198849\n",
      "Char:  e  Loss:  3.9592443   Loss so far:  7.555112020389454\n",
      "Char:  e  Loss:  6.9029474   Loss so far:  7.53794979421716\n",
      "Char:  d  Loss:  10.932711   Loss so far:  7.624994944303464\n",
      "Char:  f  Loss:  14.74969   Loss so far:  7.803112322092057\n",
      "Char:  u  Loss:  8.544023   Loss so far:  7.821183303507363\n",
      "Char:  l  Loss:  8.657742   Loss so far:  7.841101356915066\n",
      "Char:     Loss:  3.0896354   Loss so far:  7.730602147967317\n",
      "Char:  w  Loss:  10.112339   Loss so far:  7.7847325314175\n",
      "Char:  o  Loss:  7.7868295   Loss so far:  7.7847791300879585\n",
      "Char:  e  Loss:  4.1754475   Loss so far:  7.706315398216248\n",
      "Char:  ,  Loss:  1.0789007   Loss so far:  7.565306574740308\n",
      "Char:  \n",
      "  Loss:  2.8007705   Loss so far:  7.466045406957467\n",
      "Char:  S  Loss:  23.05337   Loss so far:  7.784154062368432\n",
      "Char:  i  Loss:  1.8179449   Loss so far:  7.664829878807068\n",
      "Char:  n  Loss:  7.700408   Loss so far:  7.665527488671097\n",
      "Char:  c  Loss:  11.848764   Loss so far:  7.745974352726569\n",
      "Char:  e  Loss:  12.45771   Loss so far:  7.834875030337639\n",
      "Char:     Loss:  7.5770164   Loss so far:  7.830099869657446\n",
      "Char:  i  Loss:  0.44359374   Loss so far:  7.695799758217552\n",
      "Char:  t  Loss:  17.40512   Loss so far:  7.869180491992405\n",
      "Char:     Loss:  7.958756   Loss so far:  7.870751991606595\n",
      "Char:  h  Loss:  7.3321204   Loss so far:  7.861465240346974\n",
      "Char:  a  Loss:  1.2006074   Loss so far:  7.748569345070144\n",
      "Char:  t  Loss:  9.698062   Loss so far:  7.781060888369878\n",
      "Char:  h  Loss:  14.376244   Loss so far:  7.8891786375983814\n",
      "Char:     Loss:  9.409105   Loss so far:  7.913693583780719\n",
      "Char:  b  Loss:  11.612677   Loss so far:  7.972407600236317\n",
      "Char:  e  Loss:  0.048784465   Loss so far:  7.848600988741964\n",
      "Char:  e  Loss:  10.046752   Loss so far:  7.882418696238444\n",
      "Char:  n  Loss:  13.942167   Loss so far:  7.974233068751566\n",
      "Char:     Loss:  6.5029726   Loss so far:  7.952273957320114\n",
      "Char:  b  Loss:  13.977255   Loss so far:  8.040876617764726\n",
      "Char:  e  Loss:  2.0098886   Loss so far:  7.953470995028813\n",
      "Char:  f  Loss:  5.517074   Loss so far:  7.918665325215884\n",
      "Char:  o  Loss:  4.3872647   Loss so far:  7.8689272886430714\n",
      "Char:  r  Loss:  12.772125   Loss so far:  7.937027260247204\n",
      "Char:  e  Loss:  6.275036   Loss so far:  7.914260254739082\n",
      "Char:  h  Loss:  3.342887   Loss so far:  7.852484939468874\n",
      "Char:  a  Loss:  2.4837656   Loss so far:  7.7809020149707795\n",
      "Char:  n  Loss:  8.875488   Loss so far:  7.795304465842874\n",
      "Char:  d  Loss:  7.0542107   Loss so far:  7.785679870998704\n",
      "Char:     Loss:  4.7124863   Loss so far:  7.746279952999873\n",
      "Char:  w  Loss:  13.098381   Loss so far:  7.814028068056589\n",
      "Char:  i  Loss:  5.8194833   Loss so far:  7.789096258208156\n",
      "Char:  t  Loss:  4.114009   Loss so far:  7.7437248093846405\n",
      "Char:  h  Loss:  7.37865   Loss so far:  7.739272679860999\n",
      "Char:     Loss:  6.922788   Loss so far:  7.729435516768191\n",
      "Char:  o  Loss:  1.6566955   Loss so far:  7.657140992581844\n",
      "Char:  u  Loss:  13.064974   Loss so far:  7.720762555388843\n",
      "Char:  r  Loss:  6.679508   Loss so far:  7.70865494671256\n",
      "Char:     Loss:  10.713611   Loss so far:  7.743194667429759\n",
      "Char:  g  Loss:  13.650404   Loss so far:  7.810322045941245\n",
      "Char:  r  Loss:  4.577553   Loss so far:  7.773998795935277\n",
      "Char:  i  Loss:  8.69126   Loss so far:  7.784190590845214\n",
      "Char:  e  Loss:  2.309694   Loss so far:  7.724031288217712\n",
      "Char:  f  Loss:  10.668863   Loss so far:  7.756040331786093\n",
      "Char:  s  Loss:  0.7185284   Loss so far:  7.680368160368294\n",
      "Char:  .  Loss:  8.049294   Loss so far:  7.684292908361617\n",
      "Char:  \n",
      "  Loss:  1.2159404   Loss so far:  7.616204986760491\n",
      "Char:  T  Loss:  14.141541   Loss so far:  7.6841772319749\n",
      "Char:  h  Loss:  10.589302   Loss so far:  7.714126972500811\n",
      "Char:  i  Loss:  4.512639   Loss so far:  7.681458728349939\n",
      "Char:  s  Loss:  6.454192   Loss so far:  7.669062096362162\n",
      "Char:     Loss:  7.3674684   Loss so far:  7.666046158969403\n",
      "Char:  E  Loss:  12.938505   Loss so far:  7.718248723462077\n",
      "Char:  n  Loss:  10.372784   Loss so far:  7.744273575789788\n",
      "Char:  g  Loss:  17.081633   Loss so far:  7.834927547035865\n",
      "Char:  l  Loss:  9.897542   Loss so far:  7.854760378312606\n",
      "Char:  a  Loss:  6.8783855   Loss so far:  7.845461570365089\n",
      "Char:  n  Loss:  12.401141   Loss so far:  7.8884396797643515\n",
      "Char:  d  Loss:  16.307713   Loss so far:  7.967124472990214\n",
      "Char:     Loss:  7.7491345   Loss so far:  7.965106047689915\n",
      "Char:  n  Loss:  5.6281404   Loss so far:  7.943665996330593\n",
      "Char:  e  Loss:  5.1868944   Loss so far:  7.918604436516762\n",
      "Char:  v  Loss:  10.680892   Loss so far:  7.943489909977527\n",
      "Char:  e  Loss:  0.22891027   Loss so far:  7.874609734596951\n",
      "Char:  r  Loss:  11.609764   Loss so far:  7.907664197999819\n",
      "Char:     Loss:  2.6799989   Loss so far:  7.861807484637227\n",
      "Char:  d  Loss:  14.159113   Loss so far:  7.916566662425581\n",
      "Char:  i  Loss:  2.8463209   Loss so far:  7.872857646952415\n",
      "Char:  d  Loss:  4.987347   Loss so far:  7.848195163867413\n",
      "Char:  ,  Loss:  12.968409   Loss so far:  7.891586803026119\n",
      "Char:     Loss:  6.3425417   Loss so far:  7.878569617241371\n",
      "Char:  n  Loss:  12.381808   Loss so far:  7.916096606105566\n",
      "Char:  o  Loss:  15.799898   Loss so far:  7.981251990745876\n",
      "Char:  r  Loss:  10.011646   Loss so far:  7.997894566811499\n",
      "Char:     Loss:  6.7280297   Loss so far:  7.987570462430396\n",
      "Char:  n  Loss:  5.4827156   Loss so far:  7.967370020045388\n",
      "Char:  e  Loss:  3.8444538   Loss so far:  7.934386690378189\n",
      "Char:  v  Loss:  14.124016   Loss so far:  7.983510730995072\n",
      "Char:  e  Loss:  9.491115   Loss so far:  7.995381627730497\n",
      "Char:  r  Loss:  11.389999   Loss so far:  8.021902078995481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char:     Loss:  1.5112951   Loss so far:  7.971432257299275\n",
      "Char:  s  Loss:  13.452825   Loss so far:  8.013596813724591\n",
      "Char:  h  Loss:  13.029382   Loss so far:  8.051885248368023\n",
      "Char:  a  Loss:  8.631401   Loss so far:  8.056275519683506\n",
      "Char:  l  Loss:  6.031267   Loss so far:  8.041049892965116\n",
      "Char:  l  Loss:  12.0220375   Loss so far:  8.070758755749731\n",
      "Char:  ,  Loss:  10.18743   Loss so far:  8.086437804831398\n",
      "Char:  \n",
      "  Loss:  6.305746   Loss so far:  8.073344483314191\n",
      "Char:  L  Loss:  16.297071   Loss so far:  8.133371687501016\n",
      "Char:  i  Loss:  5.9173455   Loss so far:  8.117313526894735\n",
      "Char:  e  Loss:  3.6470494   Loss so far:  8.085153353514432\n",
      "Char:     Loss:  0.062310994   Loss so far:  8.027847336658409\n",
      "Char:  a  Loss:  3.0146577   Loss so far:  7.992292800482283\n",
      "Char:  t  Loss:  5.7651725   Loss so far:  7.976608854574217\n",
      "Char:     Loss:  11.23191   Loss so far:  7.999373196513503\n",
      "Char:  t  Loss:  12.260087   Loss so far:  8.02896148690747\n",
      "Char:  h  Loss:  10.309662   Loss so far:  8.04469045503386\n",
      "Char:  e  Loss:  2.0384748   Loss so far:  8.003551991630907\n",
      "Char:     Loss:  0.45327413   Loss so far:  7.9521895572036305\n",
      "Char:  p  Loss:  7.649099   Loss so far:  7.950141647176163\n",
      "Char:  r  Loss:  2.6113663   Loss so far:  7.914310939960032\n",
      "Char:  o  Loss:  5.2410183   Loss so far:  7.896488988995552\n",
      "Char:  u  Loss:  15.891078   Loss so far:  7.94943328705055\n",
      "Char:  d  Loss:  12.087791   Loss so far:  7.97665932754937\n",
      "Char:     Loss:  5.4560394   Loss so far:  7.960184687687681\n",
      "Char:  f  Loss:  7.7958546   Loss so far:  7.959117608991536\n",
      "Char:  o  Loss:  5.3058147   Loss so far:  7.94199952598541\n",
      "Char:  o  Loss:  17.811691   Loss so far:  8.00526678084563\n",
      "Char:  t  Loss:  17.371466   Loss so far:  8.064924098693641\n",
      "Char:     Loss:  7.7347546   Loss so far:  8.062834418084048\n",
      "Char:  o  Loss:  2.9457383   Loss so far:  8.03065142372869\n",
      "Char:  f  Loss:  8.517441   Loss so far:  8.033693857304751\n",
      "Char:     Loss:  2.1476643   Loss so far:  7.997134667560921\n",
      "Char:  a  Loss:  0.5493342   Loss so far:  7.951160590773747\n",
      "Char:     Loss:  3.9044785   Loss so far:  7.926334320584689\n",
      "Char:  c  Loss:  6.0527034   Loss so far:  7.9149097416822505\n",
      "Char:  o  Loss:  5.052926   Loss so far:  7.897564386057131\n",
      "Char:  n  Loss:  5.3104925   Loss so far:  7.881979615752956\n",
      "Char:  q  Loss:  17.880253   Loss so far:  7.941849515288176\n",
      "Char:  u  Loss:  9.763721   Loss so far:  7.952693991185654\n",
      "Char:  e  Loss:  6.5596037   Loss so far:  7.944450853315331\n",
      "Char:  r  Loss:  7.1211195   Loss so far:  7.939607727702926\n",
      "Char:  o  Loss:  9.6882715   Loss so far:  7.949833831766195\n",
      "Char:  r  Loss:  14.761476   Loss so far:  7.98943639997133\n",
      "Char:  ,  Loss:  3.0894673   Loss so far:  7.96111287908747\n",
      "Char:  \n",
      "  Loss:  4.4119105   Loss so far:  7.940715164459985\n",
      "Char:  B  Loss:  24.377623   Loss so far:  8.0346403498309\n",
      "Char:  u  Loss:  7.345712   Loss so far:  8.030725985257464\n",
      "Char:  t  Loss:  7.745893   Loss so far:  8.029116759360846\n",
      "Char:     Loss:  4.0878887   Loss so far:  8.006975028789446\n",
      "Char:  w  Loss:  7.3248825   Loss so far:  8.00316445604383\n",
      "Char:  h  Loss:  9.3976145   Loss so far:  8.01091140061617\n",
      "Char:  e  Loss:  8.621868   Loss so far:  8.01428685217931\n",
      "Char:  n  Loss:  10.509088   Loss so far:  8.0279945483902\n",
      "Char:     Loss:  5.2749195   Loss so far:  8.012950422496743\n",
      "Char:  i  Loss:  1.4352347   Loss so far:  7.977201967297689\n",
      "Char:  t  Loss:  12.223704   Loss so far:  8.000156034166748\n",
      "Char:     Loss:  4.2038245   Loss so far:  7.979745649682578\n",
      "Char:  f  Loss:  16.256521   Loss so far:  8.024006481636016\n",
      "Char:  i  Loss:  2.9547768   Loss so far:  7.997042493775804\n",
      "Char:  r  Loss:  6.842227   Loss so far:  7.990932358793481\n",
      "Char:  s  Loss:  6.587428   Loss so far:  7.983545494236444\n",
      "Char:  t  Loss:  11.516316   Loss so far:  8.0020416770618\n",
      "Char:     Loss:  7.28413   Loss so far:  7.998302554246038\n",
      "Char:  d  Loss:  14.663334   Loss so far:  8.032836395378558\n",
      "Char:  i  Loss:  4.56486   Loss so far:  8.014960227706998\n",
      "Char:  d  Loss:  6.209925   Loss so far:  8.005703637691644\n",
      "Char:     Loss:  6.6317677   Loss so far:  7.998693760712536\n",
      "Char:  h  Loss:  6.039361   Loss so far:  7.988747909135625\n",
      "Char:  e  Loss:  4.6540728   Loss so far:  7.971906115460878\n",
      "Char:  l  Loss:  1.9272085   Loss so far:  7.941530750774259\n",
      "Char:  p  Loss:  7.8668394   Loss so far:  7.941157294064761\n",
      "Char:     Loss:  1.1527784   Loss so far:  7.907384264676725\n",
      "Char:  t  Loss:  14.466921   Loss so far:  7.939857218082588\n",
      "Char:  o  Loss:  0.07431734   Loss so far:  7.9011107162375165\n",
      "Char:     Loss:  6.876491   Loss so far:  7.896088070911812\n",
      "Char:  w  Loss:  9.164293   Loss so far:  7.902274437830216\n",
      "Char:  o  Loss:  5.0088177   Loss so far:  7.888228531203513\n",
      "Char:  u  Loss:  9.316048   Loss so far:  7.895126208195076\n",
      "Char:  n  Loss:  11.989778   Loss so far:  7.91481203202588\n",
      "Char:  d  Loss:  11.143419   Loss so far:  7.930259913526939\n",
      "Char:     Loss:  4.5056887   Loss so far:  7.913952431402036\n",
      "Char:  i  Loss:  0.20536524   Loss so far:  7.877418842819912\n",
      "Char:  t  Loss:  7.1246176   Loss so far:  7.873867893450946\n",
      "Char:  s  Loss:  9.953538   Loss so far:  7.883631602594271\n",
      "Char:  e  Loss:  5.9695807   Loss so far:  7.874687439265931\n",
      "Char:  l  Loss:  4.895614   Loss so far:  7.860831284419048\n",
      "Char:  f  Loss:  7.6952076   Loss so far:  7.860064508082966\n",
      "Char:  .  Loss:  6.139908   Loss so far:  7.8521375188149065\n",
      "Char:  \n",
      "  Loss:  0.73173505   Loss so far:  7.8194751221720775\n",
      "Char:  N  Loss:  18.653332   Loss so far:  7.868944787169428\n",
      "Char:  o  Loss:  12.597177   Loss so far:  7.890436749736017\n",
      "Char:  w  Loss:  7.1997447   Loss so far:  7.887311446349815\n",
      "Char:     Loss:  5.2067976   Loss so far:  7.875237059653611\n",
      "Char:  t  Loss:  11.025783   Loss so far:  7.889365066494375\n",
      "Char:  h  Loss:  11.343635   Loss so far:  7.9047859126502384\n",
      "Char:  e  Loss:  8.340465   Loss so far:  7.906722262336148\n",
      "Char:  s  Loss:  8.221873   Loss so far:  7.9081167358806175\n",
      "Char:  e  Loss:  7.0739803   Loss so far:  7.904442126169341\n",
      "Char:     Loss:  8.562733   Loss so far:  7.907329365513043\n",
      "Char:  h  Loss:  5.3441796   Loss so far:  7.896136571909403\n",
      "Char:  e  Loss:  7.332973   Loss so far:  7.89368803465496\n",
      "Char:  r  Loss:  5.840246   Loss so far:  7.88479867606581\n",
      "Char:     Loss:  2.435126   Loss so far:  7.861308707919871\n",
      "Char:  p  Loss:  10.078664   Loss so far:  7.870825253490982\n",
      "Char:  r  Loss:  2.26912   Loss so far:  7.846886342057051\n",
      "Char:  i  Loss:  1.7561436   Loss so far:  7.820968287707643\n",
      "Char:  n  Loss:  11.41691   Loss so far:  7.836205329588156\n",
      "Char:  c  Loss:  3.4332833   Loss so far:  7.817627599627912\n",
      "Char:  e  Loss:  10.050476   Loss so far:  7.827009315907705\n",
      "Char:  s  Loss:  0.042958703   Loss so far:  7.794440066480861\n",
      "Char:     Loss:  1.101007   Loss so far:  7.766550761973486\n",
      "Char:  a  Loss:  3.698202   Loss so far:  7.749669646341895\n",
      "Char:  r  Loss:  1.3982803   Loss so far:  7.72342423566671\n",
      "Char:  e  Loss:  8.462439   Loss so far:  7.726465446974147\n",
      "Char:     Loss:  7.2649403   Loss so far:  7.724573950313765\n",
      "Char:  c  Loss:  11.840494   Loss so far:  7.741373624622214\n",
      "Char:  o  Loss:  4.934901   Loss so far:  7.729965200284269\n",
      "Char:  m  Loss:  5.0122337   Loss so far:  7.718962238882838\n",
      "Char:  e  Loss:  4.0695887   Loss so far:  7.704247022843769\n",
      "Char:     Loss:  6.902782   Loss so far:  7.701028287665073\n",
      "Char:  h  Loss:  5.8380985   Loss so far:  7.6935765686184165\n",
      "Char:  o  Loss:  7.634234   Loss so far:  7.693340143849294\n",
      "Char:  m  Loss:  9.30915   Loss so far:  7.6997520866996005\n",
      "Char:  e  Loss:  2.2052875   Loss so far:  7.678034835196884\n",
      "Char:     Loss:  2.9194717   Loss so far:  7.659300334824938\n",
      "Char:  a  Loss:  2.2690566   Loss so far:  7.638162123937817\n",
      "Char:  g  Loss:  6.3910246   Loss so far:  7.63329049294407\n",
      "Char:  a  Loss:  6.1910467   Loss so far:  7.627678649449279\n",
      "Char:  i  Loss:  9.512842   Loss so far:  7.634985484832595\n",
      "Char:  n  Loss:  21.818644   Loss so far:  7.689748643462377\n",
      "Char:  ,  Loss:  9.765443   Loss so far:  7.697732082711389\n",
      "Char:  \n",
      "  Loss:  7.4735966   Loss so far:  7.696873325968725\n",
      "Char:  C  Loss:  20.426403   Loss so far:  7.745459317265235\n",
      "Char:  o  Loss:  6.283779   Loss so far:  7.739901597976345\n",
      "Char:  m  Loss:  2.8397584   Loss so far:  7.721340449484573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char:  e  Loss:  2.8283436   Loss so far:  7.702876310542507\n",
      "Char:     Loss:  5.3422327   Loss so far:  7.694001710518522\n",
      "Char:  t  Loss:  10.979652   Loss so far:  7.706307518362218\n",
      "Char:  h  Loss:  10.636942   Loss so far:  7.717242721315307\n",
      "Char:  e  Loss:  11.379452   Loss so far:  7.730856881279595\n",
      "Char:     Loss:  0.8852723   Loss so far:  7.705502864401097\n",
      "Char:  t  Loss:  10.356767   Loss so far:  7.715286125789819\n",
      "Char:  h  Loss:  5.7650995   Loss so far:  7.708116322112105\n",
      "Char:  r  Loss:  3.1596265   Loss so far:  7.691455187173663\n",
      "Char:  e  Loss:  0.39059842   Loss so far:  7.664809724506345\n",
      "Char:  e  Loss:  8.98829   Loss so far:  7.669622379446571\n",
      "Char:     Loss:  2.2109816   Loss so far:  7.649844695490016\n",
      "Char:  c  Loss:  11.459836   Loss so far:  7.663599176755989\n",
      "Char:  o  Loss:  3.2497616   Loss so far:  7.647722063103704\n",
      "Char:  r  Loss:  4.961821   Loss so far:  7.638095177856932\n",
      "Char:  n  Loss:  4.511832   Loss so far:  7.626929953069027\n",
      "Char:  e  Loss:  11.46307   Loss so far:  7.640581696708537\n",
      "Char:  r  Loss:  12.602933   Loss so far:  7.658178686897489\n",
      "Char:  s  Loss:  1.9527125   Loss so far:  7.638018029119964\n",
      "Char:     Loss:  8.981801   Loss so far:  7.6427496594153865\n",
      "Char:  o  Loss:  3.412306   Loss so far:  7.62790599769929\n",
      "Char:  f  Loss:  5.4670296   Loss so far:  7.620350485719689\n",
      "Char:     Loss:  1.2401011   Loss so far:  7.59811965161967\n",
      "Char:  t  Loss:  10.888842   Loss so far:  7.6095457695967825\n",
      "Char:  h  Loss:  12.758459   Loss so far:  7.627362078668027\n",
      "Char:  e  Loss:  5.666613   Loss so far:  7.620600875300066\n",
      "Char:     Loss:  1.8367645   Loss so far:  7.600725148769281\n",
      "Char:  w  Loss:  9.701071   Loss so far:  7.60791811327871\n",
      "Char:  o  Loss:  5.225887   Loss so far:  7.599788313648908\n",
      "Char:  r  Loss:  15.898321   Loss so far:  7.628014615819263\n",
      "Char:  l  Loss:  14.125661   Loss so far:  7.650040535414118\n",
      "Char:  d  Loss:  19.74931   Loss so far:  7.690916444212702\n",
      "Char:     Loss:  2.2127995   Loss so far:  7.672471606182029\n",
      "Char:  i  Loss:  2.930909   Loss so far:  7.6565603219947755\n",
      "Char:  n  Loss:  11.695045   Loss so far:  7.670066961289748\n",
      "Char:     Loss:  9.173846   Loss so far:  7.675079558901489\n",
      "Char:  a  Loss:  1.5548259   Loss so far:  7.65474649027386\n",
      "Char:  r  Loss:  9.262111   Loss so far:  7.6600688883529005\n",
      "Char:  m  Loss:  9.437176   Loss so far:  7.6659339275026674\n",
      "Char:  s  Loss:  8.647093   Loss so far:  7.6691614238569805\n",
      "Char:  ,  Loss:  8.361481   Loss so far:  7.6714313231652875\n",
      "Char:  \n",
      "  Loss:  10.738073   Loss so far:  7.681453029132065\n",
      "Char:  A  Loss:  13.645012   Loss so far:  7.700878302333118\n",
      "Char:  n  Loss:  11.374298   Loss so far:  7.71280498997393\n",
      "Char:  d  Loss:  17.29406   Loss so far:  7.743812286943005\n",
      "Char:     Loss:  3.9331605   Loss so far:  7.731519861963968\n",
      "Char:  w  Loss:  9.326844   Loss so far:  7.736649522264384\n",
      "Char:  e  Loss:  0.1667489   Loss so far:  7.712387020257899\n",
      "Char:     Loss:  8.237643   Loss so far:  7.714065155151268\n",
      "Char:  s  Loss:  15.381683   Loss so far:  7.7384843213756564\n",
      "Char:  h  Loss:  14.930877   Loss so far:  7.761317313155011\n",
      "Char:  a  Loss:  5.514681   Loss so far:  7.754207704133719\n",
      "Char:  l  Loss:  0.14953443   Loss so far:  7.730218198549954\n",
      "Char:  l  Loss:  11.056244   Loss so far:  7.740677398857924\n",
      "Char:     Loss:  6.606318   Loss so far:  7.737121413272096\n",
      "Char:  s  Loss:  15.679585   Loss so far:  7.761941613408271\n",
      "Char:  h  Loss:  11.343289   Loss so far:  7.7730984600185415\n",
      "Char:  o  Loss:  4.8779736   Loss so far:  7.76410738888966\n",
      "Char:  c  Loss:  16.490276   Loss so far:  7.791123391823964\n",
      "Char:  k  Loss:  14.753222   Loss so far:  7.812611351927949\n",
      "Char:     Loss:  6.6761255   Loss so far:  7.809114472464874\n",
      "Char:  t  Loss:  14.923517   Loss so far:  7.830937793798333\n",
      "Char:  h  Loss:  10.074766   Loss so far:  7.837799654242551\n",
      "Char:  e  Loss:  2.1290715   Loss so far:  7.820394995156676\n",
      "Char:  m  Loss:  4.195192   Loss so far:  7.809376140643126\n",
      "Char:  .  Loss:  9.667349   Loss so far:  7.8150063610099485\n",
      "Char:     Loss:  0.11561714   Loss so far:  7.791745366387947\n",
      "Char:  N  Loss:  16.614676   Loss so far:  7.818320457217654\n",
      "Char:  o  Loss:  9.263912   Loss so far:  7.8226615735651315\n",
      "Char:  u  Loss:  13.546772   Loss so far:  7.8397996287436005\n",
      "Char:  g  Loss:  6.2216043   Loss so far:  7.834969195067438\n",
      "Char:  h  Loss:  3.921567   Loss so far:  7.823322164615439\n",
      "Char:  t  Loss:  10.33504   Loss so far:  7.830775333540818\n",
      "Char:     Loss:  8.815671   Loss so far:  7.833689225947804\n",
      "Char:  s  Loss:  17.250517   Loss so far:  7.861467478648487\n",
      "Char:  h  Loss:  11.900407   Loss so far:  7.873346712056766\n",
      "Char:  a  Loss:  5.7416844   Loss so far:  7.867095503038413\n",
      "Char:  l  Loss:  1.3508108   Loss so far:  7.848042038895669\n",
      "Char:  l  Loss:  12.422232   Loss so far:  7.86137786873619\n",
      "Char:     Loss:  9.594003   Loss so far:  7.866414568895951\n",
      "Char:  m  Loss:  11.771372   Loss so far:  7.877733285627936\n",
      "Char:  a  Loss:  8.013224   Loss so far:  7.878124876270835\n",
      "Char:  k  Loss:  10.607997   Loss so far:  7.88599194273868\n",
      "Char:  e  Loss:  11.317374   Loss so far:  7.895852236665957\n",
      "Char:     Loss:  5.5304656   Loss so far:  7.88907462453475\n",
      "Char:  u  Loss:  4.258328   Loss so far:  7.878701062638845\n",
      "Char:  s  Loss:  9.182398   Loss so far:  7.882415298478641\n",
      "Char:     Loss:  4.4884663   Loss so far:  7.872773397809149\n",
      "Char:  r  Loss:  3.2854037   Loss so far:  7.859778016309647\n",
      "Char:  u  Loss:  5.515934   Loss so far:  7.85315698798809\n",
      "Char:  e  Loss:  6.830455   Loss so far:  7.85027613682856\n",
      "Char:  ,  Loss:  7.0728407   Loss so far:  7.84809232939537\n",
      "Char:  \n",
      "  Loss:  7.973402   Loss so far:  7.848443336941364\n",
      "Char:  I  Loss:  15.784315   Loss so far:  7.870610576528827\n",
      "Char:  f  Loss:  6.609131   Loss so far:  7.867096705450404\n",
      "Char:     Loss:  11.587464   Loss so far:  7.87743105997021\n",
      "Char:  E  Loss:  9.240841   Loss so far:  7.881207818562717\n",
      "Char:  n  Loss:  9.268622   Loss so far:  7.885040455523528\n",
      "Char:  g  Loss:  13.722936   Loss so far:  7.9011228115043854\n",
      "Char:  l  Loss:  13.0301895   Loss so far:  7.915213654094099\n",
      "Char:  a  Loss:  11.149636   Loss so far:  7.924075085914707\n",
      "Char:  n  Loss:  16.296312   Loss so far:  7.946950051068364\n",
      "Char:  d  Loss:  19.018974   Loss so far:  7.977119054482889\n",
      "Char:     Loss:  4.984232   Loss so far:  7.968986209087155\n",
      "Char:  t  Loss:  12.059296   Loss so far:  7.980071058532167\n",
      "Char:  o  Loss:  2.1649199   Loss so far:  7.96435443365292\n",
      "Char:     Loss:  6.3597474   Loss so far:  7.960029347335312\n",
      "Char:  i  Loss:  0.9711631   Loss so far:  7.941242072460873\n",
      "Char:  t  Loss:  11.122371   Loss so far:  7.949770567494247\n",
      "Char:  s  Loss:  8.406408   Loss so far:  7.950991524024841\n",
      "Char:  e  Loss:  0.47926152   Loss so far:  7.931066910674175\n",
      "Char:  l  Loss:  3.2064888   Loss so far:  7.9185015434855\n",
      "Char:  f  Loss:  15.214487   Loss so far:  7.93785429025558\n",
      "Char:     Loss:  3.4192152   Loss so far:  7.925900218594405\n",
      "Char:  d  Loss:  17.915443   Loss so far:  7.952257852372283\n",
      "Char:  o  Loss:  8.238776   Loss so far:  7.953011848042278\n",
      "Char:     Loss:  7.3444667   Loss so far:  7.9514146166464945\n",
      "Char:  r  Loss:  2.199118   Loss so far:  7.936356248275538\n",
      "Char:  e  Loss:  0.37981284   Loss so far:  7.9166263699161945\n",
      "Char:  s  Loss:  1.9232792   Loss so far:  7.901018694906573\n",
      "Char:  t  Loss:  8.692743   Loss so far:  7.903075122455885\n",
      "Char:     Loss:  3.501639   Loss so far:  7.891672437914063\n",
      "Char:  b  Loss:  16.794025   Loss so far:  7.914675933994757\n",
      "Char:  u  Loss:  4.029553   Loss so far:  7.904662730393105\n",
      "Char:  t  Loss:  4.0085278   Loss so far:  7.894646959250031\n",
      "Char:     Loss:  1.0712992   Loss so far:  7.877151195752697\n",
      "Char:  t  Loss:  7.056722   Loss so far:  7.875052911784414\n",
      "Char:  r  Loss:  3.0421822   Loss so far:  7.862724159986769\n",
      "Char:  u  Loss:  7.008827   Loss so far:  7.86055139420938\n",
      "Char:  e  Loss:  13.807339   Loss so far:  7.875644763042857\n",
      "Char:  .  Loss:  6.85135   Loss so far:  7.873051611315224\n",
      "Char:  \n",
      "  Loss:  0.08223395   Loss so far:  7.853377829343457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('A', 0.0041731903, 5.4790745),\n",
       " ('S', 0.044818997, 3.1051233),\n",
       " ('T', 3.9201358e-09, 19.35714),\n",
       " ('A', 8.958436e-05, 9.32033),\n",
       " ('R', 2.0772148e-05, 10.781898),\n",
       " ('D', 3.2304508e-13, 28.760984),\n",
       " (':', 0.06545497, 2.726393),\n",
       " ('\\n', 0.21340875, 1.5445459),\n",
       " ('O', 5.6507273e-05, 9.781141),\n",
       " (',', 0.009331938, 4.6743126),\n",
       " (' ', 0.048710875, 3.021853),\n",
       " ('l', 0.0439443, 3.1248324),\n",
       " ('e', 3.4577475e-05, 10.272308),\n",
       " ('t', 0.0002240251, 8.403752),\n",
       " (' ', 3.9963896e-05, 10.127534),\n",
       " ('u', 0.00065784506, 7.326541),\n",
       " ('s', 0.0011055282, 6.807432),\n",
       " (' ', 0.07117445, 2.6426213),\n",
       " ('p', 5.064743e-06, 12.193207),\n",
       " ('a', 0.18411194, 1.6922114),\n",
       " ('y', 8.548233e-07, 13.972371),\n",
       " (' ', 0.052901696, 2.9393198),\n",
       " ('t', 1.8565926e-05, 10.894182),\n",
       " ('h', 0.010406994, 4.565277),\n",
       " ('e', 0.010567379, 4.5499835),\n",
       " (' ', 0.87679076, 0.1314869),\n",
       " ('t', 1.1998866e-05, 11.330698),\n",
       " ('i', 0.041787572, 3.1751564),\n",
       " ('m', 2.741478e-07, 15.109598),\n",
       " ('e', 0.1555866, 1.8605528),\n",
       " (' ', 0.076001756, 2.5769987),\n",
       " ('b', 1.0770993e-06, 13.741239),\n",
       " ('u', 1.7800327e-05, 10.936294),\n",
       " ('t', 8.833004e-05, 9.334431),\n",
       " (' ', 0.6356852, 0.4530518),\n",
       " ('n', 0.00014110208, 8.866027),\n",
       " ('e', 0.019077525, 3.9592443),\n",
       " ('e', 0.0010048194, 6.9029474),\n",
       " ('d', 1.7864224e-05, 10.932711),\n",
       " ('f', 3.9290796e-07, 14.74969),\n",
       " ('u', 0.00019470551, 8.544023),\n",
       " ('l', 0.00017377637, 8.657742),\n",
       " (' ', 0.04551855, 3.0896354),\n",
       " ('w', 4.057578e-05, 10.112339),\n",
       " ('o', 0.00041516716, 7.7868295),\n",
       " ('e', 0.015368313, 4.1754475),\n",
       " (',', 0.33996904, 1.0789007),\n",
       " ('\\n', 0.060763225, 2.8007705),\n",
       " ('S', 9.728564e-11, 23.05337),\n",
       " ('i', 0.16235907, 1.8179449),\n",
       " ('n', 0.0004526425, 7.700408),\n",
       " ('c', 7.1473846e-06, 11.848764),\n",
       " ('e', 3.887632e-06, 12.45771),\n",
       " (' ', 0.00051208684, 7.5770164),\n",
       " ('i', 0.6417261, 0.44359374),\n",
       " ('t', 2.7609069e-08, 17.40512),\n",
       " (' ', 0.0003495877, 7.958756),\n",
       " ('h', 0.0006541851, 7.3321204),\n",
       " ('a', 0.30101132, 1.2006074),\n",
       " ('t', 6.140238e-05, 9.698062),\n",
       " ('h', 5.7079063e-07, 14.376244),\n",
       " (' ', 8.197424e-05, 9.409105),\n",
       " ('b', 9.0506255e-06, 11.612677),\n",
       " ('e', 0.9523864, 0.048784465),\n",
       " ('e', 4.3326258e-05, 10.046752),\n",
       " ('n', 8.8103627e-07, 13.942167),\n",
       " (' ', 0.0014989764, 6.5029726),\n",
       " ('b', 8.506588e-07, 13.977255),\n",
       " ('e', 0.13400361, 2.0098886),\n",
       " ('f', 0.004017586, 5.517074),\n",
       " ('o', 0.012434697, 4.3872647),\n",
       " ('r', 2.8388104e-06, 12.772125),\n",
       " ('e', 0.0018827234, 6.275036),\n",
       " ('h', 0.0353348, 3.342887),\n",
       " ('a', 0.083428465, 2.4837656),\n",
       " ('n', 0.00013977343, 8.875488),\n",
       " ('d', 0.0008637642, 7.0542107),\n",
       " (' ', 0.008982415, 4.7124863),\n",
       " ('w', 2.0485436e-06, 13.098381),\n",
       " ('i', 0.0029691388, 5.8194833),\n",
       " ('t', 0.016342126, 4.114009),\n",
       " ('h', 0.00062444323, 7.37865),\n",
       " (' ', 0.0009850798, 6.922788),\n",
       " ('o', 0.19076833, 1.6566955),\n",
       " ('u', 2.1181365e-06, 13.064974),\n",
       " ('r', 0.0012563957, 6.679508),\n",
       " (' ', 2.224016e-05, 10.713611),\n",
       " ('g', 1.1795191e-06, 13.650404),\n",
       " ('r', 0.010280022, 4.577553),\n",
       " ('i', 0.00016804802, 8.69126),\n",
       " ('e', 0.099291615, 2.309694),\n",
       " ('f', 2.3257948e-05, 10.668863),\n",
       " ('s', 0.4874691, 0.7185284),\n",
       " ('.', 0.00031932723, 8.049294),\n",
       " ('\\n', 0.29643112, 1.2159404),\n",
       " ('T', 7.2178335e-07, 14.141541),\n",
       " ('h', 2.518399e-05, 10.589302),\n",
       " ('i', 0.010969471, 4.512639),\n",
       " ('s', 0.0015739104, 6.454192),\n",
       " (' ', 0.0006314648, 7.3674684),\n",
       " ('E', 2.4036901e-06, 12.938505),\n",
       " ('n', 3.127212e-05, 10.372784),\n",
       " ('g', 3.8154077e-08, 17.081633),\n",
       " ('l', 5.0298157e-05, 9.897542),\n",
       " ('a', 0.001029805, 6.8783855),\n",
       " ('n', 4.11389e-06, 12.401141),\n",
       " ('d', 8.272753e-08, 16.307713),\n",
       " (' ', 0.00043111548, 7.7491345),\n",
       " ('n', 0.003595255, 5.6281404),\n",
       " ('e', 0.0055893385, 5.1868944),\n",
       " ('v', 2.2979877e-05, 10.680892),\n",
       " ('e', 0.7953999, 0.22891027),\n",
       " ('r', 9.077027e-06, 11.609764),\n",
       " (' ', 0.06856322, 2.6799989),\n",
       " ('d', 7.092107e-07, 14.159113),\n",
       " ('i', 0.058057528, 2.8463209),\n",
       " ('d', 0.0068237428, 4.987347),\n",
       " (',', 2.332876e-06, 12.968409),\n",
       " (' ', 0.0017598234, 6.3425417),\n",
       " ('n', 4.1941985e-06, 12.381808),\n",
       " ('o', 1.3746474e-07, 15.799898),\n",
       " ('r', 4.4874236e-05, 10.011646),\n",
       " (' ', 0.001196889, 6.7280297),\n",
       " ('n', 0.0041580237, 5.4827156),\n",
       " ('e', 0.021398086, 3.8444538),\n",
       " ('v', 7.3454396e-07, 14.124016),\n",
       " ('e', 7.551989e-05, 9.491115),\n",
       " ('r', 1.1308009e-05, 11.389999),\n",
       " (' ', 0.22062407, 1.5112951),\n",
       " ('s', 1.4371839e-06, 13.452825),\n",
       " ('h', 2.1948822e-06, 13.029382),\n",
       " ('a', 0.00017841444, 8.631401),\n",
       " ('l', 0.0024024474, 6.031267),\n",
       " ('l', 6.010292e-06, 12.0220375),\n",
       " (',', 3.76405e-05, 10.18743),\n",
       " ('\\n', 0.0018257835, 6.305746),\n",
       " ('L', 8.3612655e-08, 16.297071),\n",
       " ('i', 0.0026923374, 5.9173455),\n",
       " ('e', 0.02606793, 3.6470494),\n",
       " (' ', 0.93959063, 0.062310994),\n",
       " ('a', 0.04906262, 3.0146577),\n",
       " ('t', 0.003134854, 5.7651725),\n",
       " (' ', 1.3244746e-05, 11.23191),\n",
       " ('t', 4.737092e-06, 12.260087),\n",
       " ('h', 3.3309705e-05, 10.309662),\n",
       " ('e', 0.13022718, 2.0384748),\n",
       " (' ', 0.6355439, 0.45327413),\n",
       " ('p', 0.0004764733, 7.649099),\n",
       " ('r', 0.07343414, 2.6113663),\n",
       " ('o', 0.0052948617, 5.2410183),\n",
       " ('u', 1.2548524e-07, 15.891078),\n",
       " ('d', 5.6278022e-06, 12.087791),\n",
       " (' ', 0.004270435, 5.4560394),\n",
       " ('f', 0.00041143713, 7.7958546),\n",
       " ('o', 0.004962654, 5.3058147),\n",
       " ('o', 1.8385741e-08, 17.811691),\n",
       " ('t', 2.8554073e-08, 17.371466),\n",
       " (' ', 0.00043735962, 7.7347546),\n",
       " ('o', 0.052563235, 2.9457383),\n",
       " ('f', 0.00019995053, 8.517441),\n",
       " (' ', 0.11675655, 2.1476643),\n",
       " ('a', 0.57733405, 0.5493342),\n",
       " (' ', 0.020151459, 3.9044785),\n",
       " ('c', 0.0023514968, 6.0527034),\n",
       " ('o', 0.0063906075, 5.052926),\n",
       " ('n', 0.0049394937, 5.3104925),\n",
       " ('q', 1.7167425e-08, 17.880253),\n",
       " ('u', 5.7500227e-05, 9.763721),\n",
       " ('e', 0.0014164466, 6.5596037),\n",
       " ('r', 0.0008078617, 7.1211195),\n",
       " ('o', 6.2006504e-05, 9.6882715),\n",
       " ('r', 3.883047e-07, 14.761476),\n",
       " (',', 0.045526203, 3.0894673),\n",
       " ('\\n', 0.012131978, 4.4119105),\n",
       " ('B', 2.5878156e-11, 24.377623),\n",
       " ('u', 0.00064535346, 7.345712),\n",
       " ('t', 0.00043251514, 7.745893),\n",
       " (' ', 0.016774615, 4.0878887),\n",
       " ('w', 0.00065893703, 7.3248825),\n",
       " ('h', 8.2921644e-05, 9.3976145),\n",
       " ('e', 0.00018012353, 8.621868),\n",
       " ('n', 2.7287355e-05, 10.509088),\n",
       " (' ', 0.0051183696, 5.2749195),\n",
       " ('i', 0.2380595, 1.4352347),\n",
       " ('t', 4.9126133e-06, 12.223704),\n",
       " (' ', 0.014938337, 4.2038245),\n",
       " ('f', 8.7072856e-08, 16.256521),\n",
       " ('i', 0.052090287, 2.9547768),\n",
       " ('r', 0.0010677231, 6.842227),\n",
       " ('s', 0.0013775784, 6.587428),\n",
       " ('t', 9.966148e-06, 11.516316),\n",
       " (' ', 0.0006863451, 7.28413),\n",
       " ('d', 4.283463e-07, 14.663334),\n",
       " ('i', 0.010411337, 4.56486),\n",
       " ('d', 0.0020093874, 6.209925),\n",
       " (' ', 0.0013178316, 6.6317677),\n",
       " ('h', 0.0023830815, 6.039361),\n",
       " ('e', 0.009522739, 4.6540728),\n",
       " ('l', 0.14555395, 1.9272085),\n",
       " ('p', 0.00038324375, 7.8668394),\n",
       " (' ', 0.31575826, 1.1527784),\n",
       " ('t', 5.2130997e-07, 14.466921),\n",
       " ('o', 0.92837703, 0.07431734),\n",
       " (' ', 0.0010317579, 6.876491),\n",
       " ('w', 0.00010471239, 9.164293),\n",
       " ('o', 0.006678796, 5.0088177),\n",
       " ('u', 8.996878e-05, 9.316048),\n",
       " ('n', 6.2073455e-06, 11.989778),\n",
       " ('d', 1.4470202e-05, 11.143419),\n",
       " (' ', 0.011045981, 4.5056887),\n",
       " ('i', 0.81434983, 0.20536524),\n",
       " ('t', 0.000805041, 7.1246176),\n",
       " ('s', 4.755909e-05, 9.953538),\n",
       " ('e', 0.0025553124, 5.9695807),\n",
       " ('l', 0.0074793133, 4.895614),\n",
       " ('f', 0.00045500242, 7.6952076),\n",
       " ('.', 0.0021551219, 6.139908),\n",
       " ('\\n', 0.4810736, 0.73173505),\n",
       " ('N', 7.924303e-09, 18.653332),\n",
       " ('o', 3.3815504e-06, 12.597177),\n",
       " ('w', 0.0007467766, 7.1997447),\n",
       " (' ', 0.0054791924, 5.2067976),\n",
       " ('t', 1.6276592e-05, 11.025783),\n",
       " ('h', 1.1844648e-05, 11.343635),\n",
       " ('e', 0.00023866154, 8.340465),\n",
       " ('s', 0.0002687112, 8.221873),\n",
       " ('e', 0.0008468555, 7.0739803),\n",
       " (' ', 0.00019109639, 8.562733),\n",
       " ('h', 0.0047758673, 5.3441796),\n",
       " ('e', 0.0006536275, 7.332973),\n",
       " ('r', 0.0029081267, 5.840246),\n",
       " (' ', 0.0875867, 2.435126),\n",
       " ('p', 4.1965468e-05, 10.078664),\n",
       " ('r', 0.103403136, 2.26912),\n",
       " ('i', 0.17270963, 1.7561436),\n",
       " ('n', 1.1007762e-05, 11.41691),\n",
       " ('c', 0.032280777, 3.4332833),\n",
       " ('e', 4.3165208e-05, 10.050476),\n",
       " ('s', 0.95795095, 0.042958703),\n",
       " (' ', 0.33253604, 1.101007),\n",
       " ('a', 0.024768023, 3.698202),\n",
       " ('r', 0.24702142, 1.3982803),\n",
       " ('e', 0.00021125637, 8.462439),\n",
       " (' ', 0.000699643, 7.2649403),\n",
       " ('c', 7.2067355e-06, 11.840494),\n",
       " ('o', 0.007191172, 4.934901),\n",
       " ('m', 0.0066560186, 5.0122337),\n",
       " ('e', 0.017084416, 4.0695887),\n",
       " (' ', 0.0010049855, 6.902782),\n",
       " ('h', 0.0029143787, 5.8380985),\n",
       " ('o', 0.00048360904, 7.634234),\n",
       " ('m', 9.059154e-05, 9.30915),\n",
       " ('e', 0.11021883, 2.2052875),\n",
       " (' ', 0.053962182, 2.9194717),\n",
       " ('a', 0.1034097, 2.2690566),\n",
       " ('g', 0.0016765372, 6.3910246),\n",
       " ('a', 0.0020476824, 6.1910467),\n",
       " ('i', 7.3896736e-05, 9.512842),\n",
       " ('n', 3.3441316e-10, 21.818644),\n",
       " (',', 5.740132e-05, 9.765443),\n",
       " ('\\n', 0.0005678822, 7.4735966),\n",
       " ('C', 1.3456308e-09, 20.426403),\n",
       " ('o', 0.0018663342, 6.283779),\n",
       " ('m', 0.05843978, 2.8397584),\n",
       " ('e', 0.059110682, 2.8283436),\n",
       " (' ', 0.0047851754, 5.3422327),\n",
       " ('t', 1.704502e-05, 10.979652),\n",
       " ('h', 2.4012357e-05, 10.636942),\n",
       " ('e', 1.1427908e-05, 11.379452),\n",
       " (' ', 0.4126018, 0.8852723),\n",
       " ('t', 3.177705e-05, 10.356767),\n",
       " ('h', 0.0031350832, 5.7650995),\n",
       " ('r', 0.042441595, 3.1596265),\n",
       " ('e', 0.67665184, 0.39059842),\n",
       " ('e', 0.00012486342, 8.98829),\n",
       " (' ', 0.10959301, 2.2109816),\n",
       " ('c', 1.0545244e-05, 11.459836),\n",
       " ('o', 0.038783457, 3.2497616),\n",
       " ('r', 0.007000169, 4.961821),\n",
       " ('n', 0.010978325, 4.511832),\n",
       " ('e', 1.0511193e-05, 11.46307),\n",
       " ('r', 3.3621404e-06, 12.602933),\n",
       " ('s', 0.14188868, 1.9527125),\n",
       " (' ', 0.00012567634, 8.981801),\n",
       " ('o', 0.03296509, 3.412306),\n",
       " ('f', 0.0042237593, 5.4670296),\n",
       " (' ', 0.28935495, 1.2401011),\n",
       " ('t', 1.8665358e-05, 10.888842),\n",
       " ('h', 2.8778738e-06, 12.758459),\n",
       " ('e', 0.0034595623, 5.666613),\n",
       " (' ', 0.15933211, 1.8367645),\n",
       " ('w', 6.12179e-05, 9.701071),\n",
       " ('o', 0.0053755906, 5.225887),\n",
       " ('r', 1.2457953e-07, 15.898321),\n",
       " ('l', 7.333366e-07, 14.125661),\n",
       " ('d', 2.6483995e-09, 19.74931),\n",
       " (' ', 0.109393954, 2.2127995),\n",
       " ('i', 0.053348523, 2.930909),\n",
       " ('n', 8.3350105e-06, 11.695045),\n",
       " (' ', 0.00010371678, 9.173846),\n",
       " ('a', 0.21122615, 1.5548259),\n",
       " ('r', 9.495466e-05, 9.262111),\n",
       " ('m', 7.970523e-05, 9.437176),\n",
       " ('s', 0.00017563665, 8.647093),\n",
       " (',', 0.00023369814, 8.361481),\n",
       " ('\\n', 2.170271e-05, 10.738073),\n",
       " ('A', 1.1858959e-06, 13.645012),\n",
       " ('n', 1.14869545e-05, 11.374298),\n",
       " ('d', 3.0852142e-08, 17.29406),\n",
       " (' ', 0.019581687, 3.9331605),\n",
       " ('w', 8.9002686e-05, 9.326844),\n",
       " ('e', 0.8464121, 0.1667489),\n",
       " (' ', 0.00026450696, 8.237643),\n",
       " ('s', 2.0884293e-07, 15.381683),\n",
       " ('h', 3.2779516e-07, 14.930877),\n",
       " ('a', 0.004027213, 5.514681),\n",
       " ('l', 0.8611088, 0.14953443),\n",
       " ('l', 1.5788266e-05, 11.056244),\n",
       " (' ', 0.0013518, 6.606318),\n",
       " ('s', 1.550396e-07, 15.679585),\n",
       " ('h', 1.18487305e-05, 11.343289),\n",
       " ('o', 0.007612426, 4.8779736),\n",
       " ('c', 6.892303e-08, 16.490276),\n",
       " ('k', 3.9152263e-07, 14.753222),\n",
       " (' ', 0.0012606531, 6.6761255),\n",
       " ('t', 3.3021664e-07, 14.923517),\n",
       " ('h', 4.212935e-05, 10.074766),\n",
       " ('e', 0.11894769, 2.1290715),\n",
       " ('m', 0.015067848, 4.195192),\n",
       " ('.', 6.331747e-05, 9.667349),\n",
       " (' ', 0.8908162, 0.11561714),\n",
       " ('N', 6.086088e-08, 16.614676),\n",
       " ('o', 9.478381e-05, 9.263912),\n",
       " ('u', 1.3083127e-06, 13.546772),\n",
       " ('g', 0.0019860568, 6.2216043),\n",
       " ('h', 0.019810027, 3.921567),\n",
       " ('t', 3.2475e-05, 10.33504),\n",
       " (' ', 0.0001483894, 8.815671),\n",
       " ('s', 3.2225216e-08, 17.250517),\n",
       " ('h', 6.787643e-06, 11.900407),\n",
       " ('a', 0.0032093576, 5.7416844),\n",
       " ('l', 0.25903016, 1.3508108),\n",
       " ('l', 4.0280356e-06, 12.422232),\n",
       " (' ', 6.8136156e-05, 9.594003),\n",
       " ('m', 7.722504e-06, 11.771372),\n",
       " ('a', 0.00033105593, 8.013224),\n",
       " ('k', 2.4717561e-05, 10.607997),\n",
       " ('e', 1.2159813e-05, 11.317374),\n",
       " (' ', 0.003964144, 5.5304656),\n",
       " ('u', 0.014145932, 4.258328),\n",
       " ('s', 0.00010283363, 9.182398),\n",
       " (' ', 0.011237869, 4.4884663),\n",
       " ('r', 0.037425477, 3.2854037),\n",
       " ('u', 0.004022169, 5.515934),\n",
       " ('e', 0.0010803667, 6.830455),\n",
       " (',', 0.00084782124, 7.0728407),\n",
       " ('\\n', 0.00034450504, 7.973402),\n",
       " ('I', 1.3962361e-07, 15.784315),\n",
       " ('f', 0.0013480029, 6.609131),\n",
       " (' ', 9.281711e-06, 11.587464),\n",
       " ('E', 9.699596e-05, 9.240841),\n",
       " ('n', 9.4338415e-05, 9.268622),\n",
       " ('g', 1.0969958e-06, 13.722936),\n",
       " ('l', 2.1931116e-06, 13.0301895),\n",
       " ('a', 1.4380511e-05, 11.149636),\n",
       " ('n', 8.3676085e-08, 16.296312),\n",
       " ('d', 5.4974842e-09, 19.018974),\n",
       " (' ', 0.0068450323, 4.984232),\n",
       " ('t', 5.790478e-06, 12.059296),\n",
       " ('o', 0.11475913, 2.1649199),\n",
       " (' ', 0.0017298034, 6.3597474),\n",
       " ('i', 0.37864238, 0.9711631),\n",
       " ('t', 1.4778003e-05, 11.122371),\n",
       " ('s', 0.00022343086, 8.406408),\n",
       " ('e', 0.6192405, 0.47926152),\n",
       " ('l', 0.040498562, 3.2064888),\n",
       " ('f', 2.4684954e-07, 15.214487),\n",
       " (' ', 0.032738116, 3.4192152),\n",
       " ('d', 1.6573775e-08, 17.915443),\n",
       " ('o', 0.00026420734, 8.238776),\n",
       " (' ', 0.0006461578, 7.3444667),\n",
       " ('r', 0.11090093, 2.199118),\n",
       " ('e', 0.6839894, 0.37981284),\n",
       " ('s', 0.146127, 1.9232792),\n",
       " ('t', 0.000167799, 8.692743),\n",
       " (' ', 0.03014793, 3.501639),\n",
       " ('b', 5.0868344e-08, 16.794025),\n",
       " ('u', 0.017782278, 4.029553),\n",
       " ('t', 0.01816011, 4.0085278),\n",
       " (' ', 0.34256318, 1.0712992),\n",
       " ('t', 0.0008615975, 7.056722),\n",
       " ('r', 0.047730617, 3.0421822),\n",
       " ('u', 0.0009038681, 7.008827),\n",
       " ('e', 1.0082056e-06, 13.807339),\n",
       " ('.', 0.0010580268, 6.85135),\n",
       " ('\\n', 0.92105645, 0.08223395)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(lossfile, 'r') as f:\n",
    "    excerpt = f.read()\n",
    "print('\\nEvaluating loss with the following excerpt:\\n')\n",
    "print(excerpt)\n",
    "evaluate_loss(model, excerpt, char_to_ix, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = model.predict(X[-100:], batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93582606\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_mean(losses.categorical_crossentropy(y[-100:], tf.convert_to_tensor(preds2))).eval(session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 397 characters\n",
      "Vocabulary size: 40 characters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.]]]),\n",
       " array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]),\n",
       " 40,\n",
       " {0: '\\n',\n",
       "  1: ' ',\n",
       "  2: ',',\n",
       "  3: '.',\n",
       "  4: ':',\n",
       "  5: 'A',\n",
       "  6: 'C',\n",
       "  7: 'B',\n",
       "  8: 'E',\n",
       "  9: 'D',\n",
       "  10: 'I',\n",
       "  11: 'L',\n",
       "  12: 'O',\n",
       "  13: 'N',\n",
       "  14: 'S',\n",
       "  15: 'R',\n",
       "  16: 'T',\n",
       "  17: 'a',\n",
       "  18: 'c',\n",
       "  19: 'b',\n",
       "  20: 'e',\n",
       "  21: 'd',\n",
       "  22: 'g',\n",
       "  23: 'f',\n",
       "  24: 'i',\n",
       "  25: 'h',\n",
       "  26: 'k',\n",
       "  27: 'm',\n",
       "  28: 'l',\n",
       "  29: 'o',\n",
       "  30: 'n',\n",
       "  31: 'q',\n",
       "  32: 'p',\n",
       "  33: 's',\n",
       "  34: 'r',\n",
       "  35: 'u',\n",
       "  36: 't',\n",
       "  37: 'w',\n",
       "  38: 'v',\n",
       "  39: 'y'},\n",
       " {'\\n': 0,\n",
       "  ' ': 1,\n",
       "  ',': 2,\n",
       "  '.': 3,\n",
       "  ':': 4,\n",
       "  'A': 5,\n",
       "  'B': 7,\n",
       "  'C': 6,\n",
       "  'D': 9,\n",
       "  'E': 8,\n",
       "  'I': 10,\n",
       "  'L': 11,\n",
       "  'N': 13,\n",
       "  'O': 12,\n",
       "  'R': 15,\n",
       "  'S': 14,\n",
       "  'T': 16,\n",
       "  'a': 17,\n",
       "  'b': 19,\n",
       "  'c': 18,\n",
       "  'd': 21,\n",
       "  'e': 20,\n",
       "  'f': 23,\n",
       "  'g': 22,\n",
       "  'h': 25,\n",
       "  'i': 24,\n",
       "  'k': 26,\n",
       "  'l': 28,\n",
       "  'm': 27,\n",
       "  'n': 30,\n",
       "  'o': 29,\n",
       "  'p': 32,\n",
       "  'q': 31,\n",
       "  'r': 34,\n",
       "  's': 33,\n",
       "  't': 36,\n",
       "  'u': 35,\n",
       "  'v': 38,\n",
       "  'w': 37,\n",
       "  'y': 39})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data(lossfile, SEQ_LENGTH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
