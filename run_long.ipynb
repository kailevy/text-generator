{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "import keras.callbacks\n",
    "from keras import optimizers\n",
    "import argparse\n",
    "import pickle\n",
    "from RNN_utils import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 4573338 characters\n",
      "Vocabulary size: 67 characters\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_LAYERS = 2\n",
    "DEFAULT_HIDDEN = 500\n",
    "DEFAULT_DROPOUT = 0.15\n",
    "\n",
    "DATA_DIR = './data/shakespeare_input.txt'\n",
    "BATCH_SIZE = 30\n",
    "SEQ_LENGTH = 50\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "# Creating training data\n",
    "X, y, VOCAB_SIZE, ix_to_char, char_to_ix = load_data(DATA_DIR, SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split testing data from training/validation data\n",
    "train_split = 0.8\n",
    "test_ind = int(round(train_split*len(X)))\n",
    "X_test = X[test_ind:]\n",
    "y_test = y[test_ind:]\n",
    "X_train = X[:test_ind]\n",
    "y_train = y[:test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_lstm_model(VOCAB_SIZE, DEFAULT_LAYERS, DEFAULT_HIDDEN, DEFAULT_DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 58538 samples, validate on 14635 samples\n",
      "Epoch 1/50\n",
      "58538/58538 [==============================] - 599s 10ms/step - loss: 2.2002 - val_loss: 1.8073\n",
      "Epoch 2/50\n",
      "58538/58538 [==============================] - 598s 10ms/step - loss: 1.6659 - val_loss: 1.6724\n",
      "Epoch 3/50\n",
      "58538/58538 [==============================] - 598s 10ms/step - loss: 1.5162 - val_loss: 1.6042\n",
      "Epoch 4/50\n",
      "58538/58538 [==============================] - 601s 10ms/step - loss: 1.4426 - val_loss: 1.5808\n",
      "Epoch 5/50\n",
      "58538/58538 [==============================] - 600s 10ms/step - loss: 1.3977 - val_loss: 1.5551\n",
      "Epoch 6/50\n",
      "32750/58538 [===============>..............] - ETA: 4:05 - loss: 1.3685"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=50, validation_split=0.2, epochs=50, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
